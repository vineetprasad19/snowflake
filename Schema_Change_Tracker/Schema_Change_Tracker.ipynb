{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc4fb15e-f9db-44eb-9f60-1b9589b755cb",
   "metadata": {
    "name": "md_title",
    "collapsed": false,
    "resultHeight": 311
   },
   "source": "# Schema Change Tracker\n\nThis utility notebook helps to log and track schema changes (e.g., dropped columns) across databases for better governance.\n\nHere's our 4 step process:\n1. SQL query to retrieve data\n2. Convert SQL table to a Pandas DataFrame\n3. Data preparation and filtering (using user input from Streamlit widgets)\n4. Data visualization and exploration"
  },
  {
   "cell_type": "markdown",
   "id": "42a7b143-0779-4706-affc-c214213f55c5",
   "metadata": {
    "name": "md_retrieve_data",
    "collapsed": false,
    "resultHeight": 128
   },
   "source": "## 1. Retrieve Data\n\nTo gain insights on query costs, we'll write a SQL query to retrieve data on *dropped columns* from the `snowflake.account_usage.columns` table.\n"
  },
  {
   "cell_type": "code",
   "id": "d549f7ac-bbbd-41f4-9ee3-98284e587de1",
   "metadata": {
    "language": "sql",
    "name": "sql_columns",
    "resultHeight": 439,
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Track dropped columns\nSELECT\n  COLUMN_ID,\n  COLUMN_NAME,\n  TABLE_ID,\n  TABLE_NAME,\n  TABLE_SCHEMA_ID,\n  TABLE_SCHEMA,\n  TABLE_CATALOG_ID,\n  TABLE_CATALOG,\n  DATA_TYPE,\n  CHARACTER_MAXIMUM_LENGTH,\n  DELETED\nFROM \n  SNOWFLAKE.ACCOUNT_USAGE.COLUMNS\nWHERE \n  DELETED >= DATEADD(days, -90, CURRENT_DATE())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a083d5e7-3edd-4f8e-987b-a188d1fe788b",
   "metadata": {
    "language": "sql",
    "name": "sql_tables",
    "resultHeight": 439,
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "-- Track dropped tables\nSELECT\n  id as table_id,\n  table_name,\n  table_created,\n  table_dropped,\n  \n  table_schema_id,\n  table_schema,\n  schema_created,\n  schema_dropped,\n  \n  table_catalog_id,\n  table_catalog,\n  catalog_created,\n  catalog_dropped\nFROM\n  SNOWFLAKE.ACCOUNT_USAGE.TABLE_STORAGE_METRICS\nWHERE\n  table_dropped >= DATEADD(days, -90, CURRENT_DATE())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5637961e-8f62-4b9f-954d-f51612761d4b",
   "metadata": {
    "language": "sql",
    "name": "sql_databases",
    "resultHeight": 439,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Track dropped databases\nSELECT\n  database_id,\n  database_name,\n  database_owner,\n  created,\n  last_altered,\n  deleted\nFROM\n  SNOWFLAKE.ACCOUNT_USAGE.DATABASES\nWHERE\n  deleted >= DATEADD(days, -90, CURRENT_DATE())",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "870b69dd-aae0-4dd3-93f7-7adce1268159",
   "metadata": {
    "name": "md_dataframe",
    "collapsed": false,
    "resultHeight": 102
   },
   "source": "## 2. Convert Table to a DataFrame\n\nNext, we'll convert the tables to a Pandas DataFrame.\n"
  },
  {
   "cell_type": "code",
   "id": "4a5559a8-ef3a-40c3-a9d5-54602403adab",
   "metadata": {
    "language": "python",
    "name": "py_columns",
    "codeCollapsed": false,
    "resultHeight": 439,
    "collapsed": false
   },
   "outputs": [],
   "source": "sql_columns.to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dbd92f00-caea-4e43-a00a-ef4161271a28",
   "metadata": {
    "language": "python",
    "name": "py_tables",
    "collapsed": false,
    "resultHeight": 439
   },
   "outputs": [],
   "source": "sql_tables.to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0b84612f-a8c8-48aa-8061-235219c0a1a9",
   "metadata": {
    "language": "python",
    "name": "py_databases",
    "collapsed": false,
    "resultHeight": 439
   },
   "outputs": [],
   "source": "sql_databases.to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "59b04137-ca95-4fb8-b216-133272349a78",
   "metadata": {
    "name": "md_data_preparation",
    "collapsed": false,
    "resultHeight": 267
   },
   "source": "## 3. Create an Interactive Widget & Data Preparation\n\nHere, we'll create an interactive widget for dynamically selecting the entity of interest (e.g. Column, Table, Schema, Catalog or Database). This would then trigger the filtering of the DataFrame accordingly.\n\n### 3.1. Create Interactive Widget\nNext, we'll reshape the data by calculating the frequency count by hour and task name, which will subsequently be used for creating the heatmap in the next step.\n"
  },
  {
   "cell_type": "code",
   "id": "e133dfd8-2f48-4250-9811-2c85b41b2db3",
   "metadata": {
    "language": "python",
    "name": "py_data_preparation",
    "resultHeight": 609,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\n\nst.header(\"Schema Change Tracker\")\nsnowflake_option = st.selectbox(\"Select an option\", (\"Column\", \n                                                     \"Table\", \n                                                     \"Schema\", \n                                                     \"Catalog\", \n                                                     \"Database\"))\nif snowflake_option == \"Column\":\n    df = py_columns.copy()\n    date_deleted = \"DELETED\"\n    col_name = \"COLUMN_NAME\"\nif snowflake_option == \"Table\":\n    df = py_tables.copy()\n    date_deleted = \"TABLE_DROPPED\"\n    col_name = \"TABLE_NAME\"\nif snowflake_option == \"Schema\":\n    df = py_tables.copy()\n    date_deleted = \"SCHEMA_DROPPED\"\n    col_name = \"SCHEMA_NAME\"\nif snowflake_option == \"Catalog\":\n    df = py_tables.copy()\n    date_deleted = \"CATALOG_DROPPED\"\n    col_name = \"CATALOG_NAME\"\nif snowflake_option == \"Database\":\n    df = py_databases.copy()\n    date_deleted = \"DELETED\"\n    col_name = \"DATABASE_NAME\"\n\nst.write(f\"You selected: `{snowflake_option}`\")\nst.dataframe(df)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fc10e390-a5d1-4bb6-9934-68e3c869b477",
   "metadata": {
    "name": "md_data_filtering",
    "collapsed": false,
    "resultHeight": 164
   },
   "source": "### 3.2. Data Filtering\n\nHere, we'll filter the DataFrame by defining the `start_date` variable, add the `WEEK` column to the DataFrame and reshape the data by applying the `groupby()` method to the DataFrame so that the data is now aggregated by `WEEK` and `col_name` (e.g. `COLUMN_NAME`, `TABLE_NAME`, `SCHEMA_NAME`, `CATALOG_NAME`, `DATABASE_NAME`)."
  },
  {
   "cell_type": "code",
   "id": "aeff0dbb-5a3d-4c15-bcc6-f19e5f2398ac",
   "metadata": {
    "language": "python",
    "name": "py_data_filtering",
    "resultHeight": 439,
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "# Data filtering\nimport pandas as pd\n\n# Get the minimum date from date column\nstart_date = pd.to_datetime(df[date_deleted]).min()\n\n# Create week numbers for x-axis\ndf['WEEK'] = pd.to_datetime(df[date_deleted]).dt.isocalendar().week\n\n# Create aggregation for heatmap\nagg_df = df.groupby(['WEEK', col_name]).size().reset_index(name='COUNT')\nagg_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "88d679a6-feef-4aad-893c-ded57e8467cb",
   "metadata": {
    "name": "md_week_legend",
    "collapsed": false,
    "resultHeight": 41
   },
   "source": "Next, we'll define what the Week numbers correspond to. Particularly, the date range for each week."
  },
  {
   "cell_type": "code",
   "id": "b38c57ea-a8e8-42b2-b3a5-6e1bb79c22ad",
   "metadata": {
    "language": "python",
    "name": "py_week_legend",
    "resultHeight": 217,
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "# Week legend\nimport pandas as pd\nfrom datetime import datetime\n\n# Get unique weeks\nweeks = sorted(df['WEEK'].unique())\n\n# Create week ranges\nfor week in weeks:\n    monday = datetime.strptime(f'2024-W{week:02d}-1', '%Y-W%W-%w')\n    print(f\"Week {week}: {monday.strftime('%b %d')} - {(monday + pd.Timedelta(days=6)).strftime('%b %d')}\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1004d933-0fbd-4fc1-982a-b73012665ce6",
   "metadata": {
    "name": "md_heatmap",
    "collapsed": false,
    "resultHeight": 102
   },
   "source": "## Creation of the Heatmap\n\nHere, we're visualizing the data as a heatmap."
  },
  {
   "cell_type": "code",
   "id": "2c2da67a-cabd-4d11-bb1d-ccd3743faeb7",
   "metadata": {
    "language": "python",
    "name": "py_heatmap",
    "resultHeight": 423,
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "# Create the heatmap\nimport pandas as pd\nimport altair as alt\nimport numpy as np\n\n\nheatmap = alt.Chart(agg_df).mark_rect(stroke='black', strokeWidth=1).encode(\n    x=alt.X('WEEK:O', \n            title='Week Number',\n            axis=alt.Axis(\n                labelAngle=0,\n                labelOverlap=False\n            )),\n    y=alt.Y(f'{col_name}:N', \n            title='',\n            axis=alt.Axis(\n                labels=True,\n                labelLimit=250,\n                tickMinStep=1,\n                labelOverlap=False,\n                labelPadding=10\n            )),\n    color=alt.Color('COUNT:Q',\n                    title=f'Number of {snowflake_option}'),\n    tooltip=['WEEK', col_name, 'COUNT']\n).properties(\n    title=f'{snowflake_option} Usage Heatmap by Week and Table (Starting from {start_date.strftime(\"%Y-%m-%d\")})',\n    width=800,\n    height=df[col_name].nunique()*20 # Multiply the number of unique values by 15 \n)\n\nst.altair_chart(heatmap, use_container_width=True)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eb3e9b67-6a6e-4218-b17a-3f8564a04d18",
   "metadata": {
    "name": "md_resources",
    "collapsed": false,
    "resultHeight": 217
   },
   "source": "## Want to learn more?\n\n- Snowflake Docs on [Account Usage](https://docs.snowflake.com/en/sql-reference/account-usage), [COLUMNS view](https://docs.snowflake.com/en/sql-reference/account-usage/columns), [TABLES view](https://docs.snowflake.com/en/sql-reference/account-usage/tables) and [DATABASES view](https://docs.snowflake.com/en/sql-reference/account-usage/databases)\n- More about [Snowflake Notebooks](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-use-with-snowflake)\n- For more inspiration on how to use Streamlit widgets in Notebooks, check out [Streamlit Docs](https://docs.streamlit.io/) and this list of what is currently supported inside [Snowflake Notebooks](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-use-with-snowflake#label-notebooks-streamlit-support)\n- Check out the [Altair User Guide](https://altair-viz.github.io/user_guide/data.html) for further information on customizing Altair charts\n"
  }
 ]
}