{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc4fb15e-f9db-44eb-9f60-1b9589b755cb",
   "metadata": {
    "name": "md_title",
    "collapsed": false,
    "resultHeight": 311
   },
   "source": "# Query Caching Effectiveness Report\n\nThis utility notebook analyzes the query cache hit rates. This is to ensure that caching is being used effectively and to reduce unnecessary compute costs.\n\nHere's our 4 step process:\n1. SQL query to retrieve data\n2. Convert SQL table to a Pandas DataFrame\n3. Data preparation and filtering (using user input from Streamlit widgets)\n4. Data visualization and exploration"
  },
  {
   "cell_type": "markdown",
   "id": "42a7b143-0779-4706-affc-c214213f55c5",
   "metadata": {
    "name": "md_retrieve_data",
    "collapsed": false,
    "resultHeight": 220
   },
   "source": "## 1. Retrieve Data\n\nThe following query filters for queries that actually scanned data, groups results by `WAREHOUSE_NAME`, and orders them by *percentage of data scanned from cache* (`percent_scanned_from_cache`). \n\nThis helps to identify which warehouses are making the most effective use of caching.\n"
  },
  {
   "cell_type": "code",
   "id": "d549f7ac-bbbd-41f4-9ee3-98284e587de1",
   "metadata": {
    "language": "sql",
    "name": "sql_query_caching",
    "resultHeight": 439,
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT \n    warehouse_name,\n    DATE_TRUNC('day', start_time) AS query_date,\n    COUNT(DISTINCT query_parameterized_hash) AS query_parameterized_hash_count,\n    COUNT(*) AS daily_executions,\n    AVG(total_elapsed_time)/1000 AS avg_execution_time,\n    SUM(total_elapsed_time)/1000 AS total_execution_time,\n    SUM(CASE WHEN bytes_scanned > 0 THEN bytes_scanned ELSE 0 END) AS daily_bytes_scanned,\n    SUM(bytes_scanned * percentage_scanned_from_cache) / NULLIF(SUM(CASE WHEN bytes_scanned > 0 THEN bytes_scanned ELSE 0 END), 0) AS daily_cache_hit_ratio,\n    MAX_BY(query_text, start_time) AS latest_query_text,\n    MAX_BY(user_name, start_time) AS latest_user_name\nFROM snowflake.account_usage.query_history qh\nWHERE start_time >= dateadd(day, -30, current_timestamp())\nGROUP BY 1, 2\nHAVING daily_bytes_scanned > 0\nORDER BY \n    query_date DESC,\n    daily_cache_hit_ratio DESC,\n    daily_bytes_scanned DESC",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "870b69dd-aae0-4dd3-93f7-7adce1268159",
   "metadata": {
    "name": "md_dataframe",
    "collapsed": false,
    "resultHeight": 102
   },
   "source": "## 2. Convert Table to a DataFrame\n\nNext, we'll convert the tables to a Pandas DataFrame.\n"
  },
  {
   "cell_type": "code",
   "id": "4a5559a8-ef3a-40c3-a9d5-54602403adab",
   "metadata": {
    "language": "python",
    "name": "py_query_caching",
    "codeCollapsed": false,
    "resultHeight": 439,
    "collapsed": false
   },
   "outputs": [],
   "source": "sql_query_caching.to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e618ffe5-481f-4105-bc3f-f5e903b45e34",
   "metadata": {
    "name": "md_data_preparation",
    "collapsed": false,
    "resultHeight": 102
   },
   "source": "## Data Preparation\n\nHere, we'll do some data preparation prior to visualization."
  },
  {
   "cell_type": "code",
   "id": "a3f93f11-dd74-42f2-bd05-410bb66931a2",
   "metadata": {
    "language": "python",
    "name": "py_data_preparation",
    "resultHeight": 439,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "df = py_query_caching.copy()\n\n# Convert QUERY_DATE to datetime\ndf['QUERY_DATE'] = pd.to_datetime(df['QUERY_DATE'])\n\n# Create WEEK_NUMBER column\ndf['WEEK_NUMBER'] = df['QUERY_DATE'].dt.isocalendar().week\n\n# Create MONTH_YEAR column\ndf['MONTH_YEAR'] = df['QUERY_DATE'].dt.strftime('%b %Y')\n\n# Group by\ngrouped_df = df.groupby('WAREHOUSE_NAME').agg({\n    'QUERY_PARAMETERIZED_HASH_COUNT': 'count',\n    'DAILY_EXECUTIONS': 'sum',\n    'AVG_EXECUTION_TIME': 'mean',\n    'TOTAL_EXECUTION_TIME': 'sum',\n    'DAILY_BYTES_SCANNED': 'sum',\n    'DAILY_CACHE_HIT_RATIO': 'mean'\n}).reset_index()\n\ngrouped_df",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "59b04137-ca95-4fb8-b216-133272349a78",
   "metadata": {
    "name": "md_bar_chart",
    "collapsed": false,
    "resultHeight": 201
   },
   "source": "## 3. Visualize Bar Chart\n\nHere, we'll visualize the data via a bar chart for the columns:\n- Query count\n- Bytes scanned\n- Percent of bytes scanned\n"
  },
  {
   "cell_type": "code",
   "id": "3b382b54-fd8a-49f5-8bc9-72ca420608ff",
   "metadata": {
    "language": "python",
    "name": "py_bar_chart",
    "resultHeight": 623,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import altair as alt\nimport pandas as pd\n\n# Create bar chart\nchart = alt.Chart(grouped_df).mark_bar().encode(\n    y=alt.Y('WAREHOUSE_NAME:N', \n            title='',\n            axis=alt.Axis(\n                labels=True,\n                labelLimit=250,\n                tickMinStep=1,\n                labelOverlap=False,\n                labelPadding=10\n            ),\n            sort='-x'),\n    x=alt.X('DAILY_CACHE_HIT_RATIO:Q', \n            title='Cache Hit Ratio'),\n    color=alt.Color('WAREHOUSE_NAME:N', legend=None),\n    tooltip=[\n        alt.Tooltip('WAREHOUSE_NAME', title='Warehouse'),\n        alt.Tooltip('DAILY_CACHE_HIT_RATIO', title='Cache Hit Ratio'),\n        alt.Tooltip('DAILY_EXECUTIONS', title='Daily Executions'),\n        alt.Tooltip('AVG_EXECUTION_TIME', title='Avg Execution Time (ms)')\n    ]\n).properties(\n    width=400,\n    height=600,\n    title='Cache Hit Ratio by Warehouse'\n).configure_axis(\n    labelFontSize=12,\n    titleFontSize=14\n).configure_title(\n    fontSize=16,\n    anchor='middle'\n)\n\n# Display the chart\nst.altair_chart(chart, use_container_width=True)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3c995961-473b-42be-b824-9c5dcb8ef041",
   "metadata": {
    "name": "md_heatmap",
    "collapsed": false,
    "resultHeight": 201
   },
   "source": "## 4. Visualize as Heatmap\n\nHere, we'll visualize the data via a heatmap for the columns:\n- Query count\n- Bytes scanned\n- Percent of bytes scanned\n"
  },
  {
   "cell_type": "code",
   "id": "02b09580-6a70-4769-a8b1-68fda0dc72bf",
   "metadata": {
    "language": "python",
    "name": "py_heatmap",
    "resultHeight": 623,
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "import pandas as pd\nimport altair as alt\n\n# Convert QUERY_DATE to datetime if it isn't already\ndf['QUERY_DATE'] = pd.to_datetime(df['QUERY_DATE'])\n\n# Format date as string for display\ndf['DATE'] = df['QUERY_DATE'].dt.strftime('%Y-%m-%d')\n\n# Aggregate data by date and warehouse\nagg_df = df.groupby(['DATE', 'WAREHOUSE_NAME'])['DAILY_CACHE_HIT_RATIO'].sum().reset_index()\n\n# Create the heatmap\nheatmap = alt.Chart(agg_df).mark_rect(stroke='black', strokeWidth=1).encode(\n   x=alt.X('DATE:O',\n           title='Date',\n           axis=alt.Axis(\n               labelAngle=90,\n               labelOverlap=False,\n               tickCount=10\n           )),\n   y=alt.Y('WAREHOUSE_NAME:N',\n           title='',\n           axis=alt.Axis(\n               labels=True,\n               labelLimit=250,\n               tickMinStep=1,\n               labelOverlap=False,\n               labelPadding=10\n           )),\n   color=alt.Color('DAILY_CACHE_HIT_RATIO:Q',\n                   title='Cache Hit Ratio',\n                   scale=alt.Scale(scheme='blues')),\n   tooltip=['DATE', 'WAREHOUSE_NAME', \n           alt.Tooltip('DAILY_CACHE_HIT_RATIO:Q', format='.2%')]\n).properties(\n   title=f'Daily Warehouse Cache Hit Ratio Heatmap',\n   width=500,\n   height=600\n)\n\n# Add configuration to make the chart more interactive\nheatmap = heatmap.configure_axis(\n   grid=False\n).configure_view(\n   strokeWidth=0\n)\n\n# Display or save the chart\nst.altair_chart(heatmap, use_container_width=True)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b9e3e4da-4674-46aa-9e91-ed8697bfef5b",
   "metadata": {
    "name": "md_pro_tip",
    "collapsed": false,
    "resultHeight": 134
   },
   "source": "ðŸ’¡ Pro tip:\n\nWhen you see a low cache scan percentage for queries that repeatedly access the same data, you can significantly improve its performance by optimizing the cache usage. This is especially true for reports or dashboards that run similar queries throughout the day."
  },
  {
   "cell_type": "markdown",
   "id": "eb3e9b67-6a6e-4218-b17a-3f8564a04d18",
   "metadata": {
    "name": "md_resources",
    "collapsed": false,
    "resultHeight": 268
   },
   "source": "## Want to learn more?\n\n- Snowflake Docs on [Account Usage](https://docs.snowflake.com/en/sql-reference/account-usage) and [QUERY_HISTORY view](https://docs.snowflake.com/en/sql-reference/account-usage/query_history)\n- More about [Snowflake Notebooks](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-use-with-snowflake)\n- For more inspiration on how to use Streamlit widgets in Notebooks, check out [Streamlit Docs](https://docs.streamlit.io/) and this list of what is currently supported inside [Snowflake Notebooks](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-use-with-snowflake#label-notebooks-streamlit-support)\n- Check out the [Altair User Guide](https://altair-viz.github.io/user_guide/data.html) for further information on customizing Altair charts\n"
  }
 ]
}