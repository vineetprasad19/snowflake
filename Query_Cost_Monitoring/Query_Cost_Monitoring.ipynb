{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc4fb15e-f9db-44eb-9f60-1b9589b755cb",
   "metadata": {
    "name": "md_title",
    "collapsed": false,
    "resultHeight": 336
   },
   "source": "# Query Cost Monitoring\n\nA notebook that breaks down compute costs by individual query, allowing teams to identify high-cost operations.\n\nHere's our 4 step process:\n1. SQL query to retrieve query cost data\n2. Convert SQL table to a Pandas DataFrame\n3. Data preparation and filtering (using user input from Streamlit widgets)\n4. Data visualization and exploration"
  },
  {
   "cell_type": "markdown",
   "id": "42a7b143-0779-4706-affc-c214213f55c5",
   "metadata": {
    "name": "md_retrieve_data",
    "collapsed": false,
    "resultHeight": 231
   },
   "source": "## 1. Retrieve Data\n\nTo gain insights on query costs, we'll write a SQL query to retrieve the `credits_used` data from the `snowflake.account_usage.metering_history` table and merging this with associated user, database, schema and warehouse information from the `snowflake.account_usage.query_history` table.\n"
  },
  {
   "cell_type": "code",
   "id": "d549f7ac-bbbd-41f4-9ee3-98284e587de1",
   "metadata": {
    "language": "sql",
    "name": "sql_data",
    "resultHeight": 511,
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "SELECT\n  query_history.query_id,\n  query_history.query_text,\n  query_history.start_time,\n  query_history.end_time,\n  query_history.user_name,\n  query_history.database_name,\n  query_history.schema_name,\n  query_history.warehouse_name,\n  query_history.warehouse_size,\n  metering_history.credits_used,\n  execution_time/1000 as execution_time_s,\nFROM\n  snowflake.account_usage.query_history\n  JOIN snowflake.account_usage.metering_history ON query_history.start_time >= metering_history.start_time\n  AND query_history.end_time <= metering_history.end_time\nWHERE\n  query_history.start_time >= DATEADD (DAY, -7, CURRENT_TIMESTAMP())\nORDER BY\n  query_history.query_id;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "870b69dd-aae0-4dd3-93f7-7adce1268159",
   "metadata": {
    "name": "md_dataframe",
    "collapsed": false,
    "resultHeight": 102
   },
   "source": "## 2. Convert Table to a DataFrame\n\nNext, we'll convert the table to a Pandas DataFrame.\n"
  },
  {
   "cell_type": "code",
   "id": "4a5559a8-ef3a-40c3-a9d5-54602403adab",
   "metadata": {
    "language": "python",
    "name": "py_dataframe",
    "codeCollapsed": false,
    "resultHeight": 511,
    "collapsed": false
   },
   "outputs": [],
   "source": "sql_data.to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "59b04137-ca95-4fb8-b216-133272349a78",
   "metadata": {
    "name": "md_data_preparation",
    "collapsed": false,
    "resultHeight": 195
   },
   "source": "## 3. Create an Interactive Slider Widget & Data Preparation\n\nHere, we'll create an interactive slider for dynamically selecting the number of days to analyze. This would then trigger the filtering of the DataFrame to the specified number of days.\n\nNext, we'll reshape the data by calculating the frequency count by hour and task name, which will subsequently be used for creating the heatmap in the next step.\n"
  },
  {
   "cell_type": "code",
   "id": "aeff0dbb-5a3d-4c15-bcc6-f19e5f2398ac",
   "metadata": {
    "language": "python",
    "name": "cell9",
    "resultHeight": 1246,
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "import pandas as pd\nimport streamlit as st\nimport altair as alt\n\n# Get data\ndf = py_dataframe.copy()\n\n# Create date filter slider\nst.subheader(\"Select time duration\")\n\ncol = st.columns(3)\n\nwith col[0]:\n    days = st.slider('Select number of days to analyze', \n                     min_value=1, \n                     max_value=7, \n                     value=7, \n                     step=1)\nwith col[1]:\n    var = st.selectbox(\"Select a variable\", ['WAREHOUSE_NAME', 'USER_NAME', 'WAREHOUSE_SIZE'])\nwith col[2]:\n    metric = st.selectbox(\"Select a metric\", [\"COUNT\", \"TOTAL_CREDITS_USED\"])\n\n# Filter data according to day duration\ndf['START_TIME'] = pd.to_datetime(df['START_TIME'])\nlatest_date = df['START_TIME'].max()\ncutoff_date = latest_date - pd.Timedelta(days=days)\nfiltered_df = df[df['START_TIME'] > cutoff_date].copy()\n    \n# Prepare data for heatmap\nfiltered_df['HOUR_OF_DAY'] = filtered_df['START_TIME'].dt.hour\nfiltered_df['HOUR_DISPLAY'] = filtered_df['HOUR_OF_DAY'].apply(lambda x: f\"{x:02d}:00\")\n    \n# Calculate frequency count by hour and query\n#agg_df = filtered_df.groupby(['QUERY_ID', 'HOUR_DISPLAY', var]).size().reset_index(name='COUNT')\n\n# Calculate frequency count and sum of credits by hour and query\nagg_df = (filtered_df.groupby(['QUERY_ID', 'HOUR_DISPLAY', var])\n          .agg(\n              COUNT=('QUERY_ID', 'size'),\n              TOTAL_CREDITS_USED=('CREDITS_USED', 'sum')\n          )\n          .reset_index()\n)\n\nst.warning(f\"Analyzing {var} data for the last {days} days!\")\n\n\n\n## Initialize the button state in session state\nif 'expanded_btn' not in st.session_state:\n    st.session_state.expanded_btn = False\n\n## Callback function to toggle the state\ndef toggle_expand():\n    st.session_state.expanded_btn = not st.session_state.expanded_btn\n\n## Create button with callback\nst.button(\n    '⊕ Expand DataFrames' if not st.session_state.expanded_btn else '⊖ Collapse DataFrames',\n    on_click=toggle_expand,\n    type='secondary' if st.session_state.expanded_btn else 'primary'\n)\n\n## State conditional\nif st.session_state.expanded_btn:\n    expand_value = True\nelse:\n    expand_value = False\n\nwith st.expander(\"See Filtered DataFrame\", expanded=expand_value):\n    st.dataframe(filtered_df.head(100))\nwith st.expander(\"See Heatmap DataFrame\", expanded=expand_value):\n    st.dataframe(agg_df)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "35f31e4e-95d5-4ee5-a146-b9e93dd9d570",
   "metadata": {
    "name": "md_heatmap",
    "collapsed": false,
    "resultHeight": 102
   },
   "source": "## 4. Create a Heatmap for Visualizing Query Cost\n\nFinally, a heatmap, and stacked bar chart, and bubble chart are generated that will allow us to gain insights on query cost and frequency."
  },
  {
   "cell_type": "code",
   "id": "414edc5e-3597-478e-aac7-f787f68bb3b1",
   "metadata": {
    "language": "python",
    "name": "py_heatmap",
    "collapsed": false,
    "resultHeight": 366,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "## Heatmap\nheatmap = alt.Chart(agg_df).mark_rect(stroke='black',strokeWidth=1).encode(\n    x='HOUR_DISPLAY:O',\n    #y='WAREHOUSE_NAME:N',\n    y=alt.Y(f'{var}:N', \n            title='',\n            axis=alt.Axis(\n                labels=True,\n                labelLimit=250,\n                tickMinStep=1,\n                labelOverlap=False,\n                labelPadding=10\n            )),\n    color=f'{metric}:Q',\n    tooltip=['HOUR_DISPLAY', var, metric]\n).properties(\n    title=f'Query Activity Heatmap by Hour and {var}'\n)\n\nst.altair_chart(heatmap, use_container_width=True)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "84ed25f3-03ef-495a-a12d-247970a29f4a",
   "metadata": {
    "language": "python",
    "name": "py_stacked_bar_chart",
    "codeCollapsed": false,
    "collapsed": false,
    "resultHeight": 423
   },
   "outputs": [],
   "source": "## Stacked bar chart with time series\nbar_time = alt.Chart(agg_df).mark_bar().encode(\n    x='HOUR_DISPLAY:O',\n    y=f'{metric}:Q',\n    color=alt.Color(f'{var}:N', legend=alt.Legend(orient='bottom')),\n    tooltip=['HOUR_DISPLAY', var, metric]\n).properties(\n    title=f'Query Activity by Hour and {var}',\n    height=400\n)\n\nst.altair_chart(bar_time, use_container_width=True)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0774909e-3ab5-48e4-92ea-c433488e96b7",
   "metadata": {
    "language": "python",
    "name": "py_bubble_plot",
    "collapsed": false,
    "resultHeight": 573,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "## Bubble plot with size representing the metric\nbubble = alt.Chart(agg_df).mark_circle().encode(\n    x='HOUR_DISPLAY:O',\n    y=alt.Y(f'{var}:N', title=''),\n    size=alt.Size(f'{metric}:Q', legend=alt.Legend(title='Query Count')),\n    color=alt.Color(f'{var}:N', legend=None),\n    tooltip=['HOUR_DISPLAY', var, metric]\n).properties(\n    title=f'Query Distribution by Hour and {var}',\n    height=550\n)\n\nst.altair_chart(bubble, use_container_width=True)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eb3e9b67-6a6e-4218-b17a-3f8564a04d18",
   "metadata": {
    "name": "md_resources",
    "collapsed": false,
    "resultHeight": 217
   },
   "source": "## Want to learn more?\n\n- Snowflake Docs on [Account Usage](https://docs.snowflake.com/en/sql-reference/account-usage), [METERING_HISTORY view](https://docs.snowflake.com/en/sql-reference/account-usage/task_history) and [QUERY_HISTORY](https://docs.snowflake.com/en/sql-reference/account-usage/query_history)\n- More about [Snowflake Notebooks](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-use-with-snowflake)\n- For more inspiration on how to use Streamlit widgets in Notebooks, check out [Streamlit Docs](https://docs.streamlit.io/) and this list of what is currently supported inside [Snowflake Notebooks](https://docs.snowflake.com/en/user-guide/ui-snowsight/notebooks-use-with-snowflake#label-notebooks-streamlit-support)\n- Check out the [Altair User Guide](https://altair-viz.github.io/user_guide/data.html) for further information on customizing Altair charts\n"
  },
  {
   "cell_type": "markdown",
   "id": "6c11317d-7fd7-412d-aeae-cd131dd1530d",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": ""
  }
 ]
}